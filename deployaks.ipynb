{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Model\n",
    "import numpy as np\n",
    "from azureml.core import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "model_dict_deos = ws.models['model-deos-statement_dict_deos']\n",
    "model_feature_dict_deos=ws.models['model-deos-statement_features_dict_deos']\n",
    "model_feature_dict_output_deos=ws.models['model-deos-statement_features_output_dict_deos']\n",
    "\n",
    "\n",
    "model_dict_zicr = ws.models['model-deos-statement_dict_zicr']\n",
    "model_feature_dict_zicr=ws.models['model-deos-statement_features_dict_zicr']\n",
    "model_feature_dict_output_zicr=ws.models['model-deos-statement_features_output_dict_zicr']\n",
    "\n",
    "model_dict_zbvg = ws.models['model-deos-statement_dict_zbvg']\n",
    "model_feature_dict_zbvg=ws.models['model-deos-statement_features_dict_zbvg']\n",
    "model_feature_dict_output_zbvg=ws.models['model-deos-statement_features_output_dict_zbvg']\n",
    "\n",
    "model_dict_zhrc = ws.models['model-deos-statement_dict_zhrc']\n",
    "model_feature_dict_zhrc=ws.models['model-deos-statement_features_dict_zhrc']\n",
    "model_feature_dict_output_zhrc=ws.models['model-deos-statement_features_output_dict_zhrc']\n",
    "\n",
    "model_dict_zsvr = ws.models['model-deos-statement_dict_zsvr']\n",
    "model_feature_dict_zsvr=ws.models['model-deos-statement_features_dict_zsvr']\n",
    "model_feature_dict_output_zsvr=ws.models['model-deos-statement_features_output_dict_zsvr']\n",
    "\n",
    "\n",
    "#print(model.name, model_feature_dict.name,model_feature_dict_output.name,'version', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statement_final_deos folder created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_name = 'statement_final_deos'\n",
    "\n",
    "# Create a folder for the web service files\n",
    "experiment_folder = './' + folder_name\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(folder_name, 'folder created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./statement_final_deos'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path for scoring script\n",
    "script_file = os.path.join(experiment_folder,\"score.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile $script_file\n",
    "# import json\n",
    "# import joblib\n",
    "# import numpy as np\n",
    "# from azureml.core.model import Model\n",
    "\n",
    "# # Called when the service is loaded\n",
    "# def init():\n",
    "#     global model_dict_deos\n",
    "#     global model_feature_dict_deos\n",
    "#     global model_feature_dict_output_deos\n",
    "    \n",
    "#     global model_dict_zicr\n",
    "#     global model_feature_zicr\n",
    "#     global model_feature_dict_zicr\n",
    "    \n",
    "#     global model_dict_zbvg\n",
    "#     global model_feature_dict_zbvg\n",
    "#     global model_feature_dict_output_zbvg\n",
    "    \n",
    "# #     global model_dict_zsvr\n",
    "# #     global model_feature_dict_zsvr\n",
    "# #     global model_feature_dict_output_zsvr\n",
    "    \n",
    "# #     global model_dict_zhrc\n",
    "# #     global model_feature_dict_zhrc\n",
    "# #     global model_feature_dict_output_zhrc\n",
    "    \n",
    "#     # Get the path to the deployed model file and load it\n",
    "#     model_path1 = Model.get_model_path('model-deos-statement_dict_deos')\n",
    "#     model_path2 = Model.get_model_path('model-deos-statement_features_dict_deos')\n",
    "#     model_path3 = Model.get_model_path('model-deos-statement_features_output_dict_deos')\n",
    "#     model_path4 = Model.get_model_path('model-deos-statement_dict_zicr')\n",
    "#     model_path5 = Model.get_model_path('model-deos-statement_features_dict_zicr')\n",
    "#     model_path6 = Model.get_model_path('model-deos-statement_features_output_dict_zicr')\n",
    "#     model_path7 = Model.get_model_path('model-deos-statement_dict_zbvg')\n",
    "#     model_path8 = Model.get_model_path('model-deos-statement_features_dict_zbvg')\n",
    "#     model_path9 = Model.get_model_path('model-deos-statement_features_output_dict_zbvg')\n",
    "# #     model_path1 = Model.get_model_path('model-deos-statement_dict_zhrc')\n",
    "# #     model_path2 = Model.get_model_path('model-deos-statement_features_dict_zhrc')\n",
    "# #     model_path3 = Model.get_model_path('model-deos-statement_features_output_dict_zhrc')\n",
    "# #     model_path1 = Model.get_model_path('model-deos-statement_dict_zsvr')\n",
    "# #     model_path2 = Model.get_model_path('model-deos-statement_features_dict_zsvr')\n",
    "# #     model_path3 = Model.get_model_path('model-deos-statement_features_output_dict_zsvr')\n",
    "\n",
    "    \n",
    "#     model_dict_deos = joblib.load(model_path1)\n",
    "#     model_feature_dict_deos = joblib.load(model_path2)\n",
    "#     model_feature_dict_output_deos = joblib.load(model_path3)\n",
    "    \n",
    "#     model_dict_zicr = joblib.load(model_path4)\n",
    "#     model_feature_dict_zicr = joblib.load(model_path5)\n",
    "#     model_feature_dict_output_zicr = joblib.load(model_path6)\n",
    "    \n",
    "#     model_dict_zbvg = joblib.load(model_path7)\n",
    "#     model_feature_dict_zbvg = joblib.load(model_path8)\n",
    "#     model_feature_dict_output_zbvg = joblib.load(model_path9)\n",
    "    \n",
    "# #     model_dict_zhrc = joblib.load(model_path10)\n",
    "# #     model_feature_dict_zhrc = joblib.load(model_path11)\n",
    "# #     model_feature_dict_output_zhrc= joblib.load(model_path12)\n",
    "    \n",
    "# #     model_dict_zsvr = joblib.load(model_path13)\n",
    "# #     model_feature_dict_zsvr = joblib.load(model_path14)\n",
    "# #     model_feature_dict_output_zsvr = joblib.load(model_path15)\n",
    "\n",
    "\n",
    "\n",
    "# # Called when a request is received\n",
    "# def run(raw_data):\n",
    "#     try:\n",
    "#         output=[]\n",
    "#         data = json.loads(raw_data)['data']\n",
    "#         int_features = data\n",
    "\n",
    "\n",
    "#         if int_features[0]=='ZDEO':\n",
    "#         # Get the input data as a numpy array\n",
    "#             l1 = list(model_feature_dict_deos.values())\n",
    "#             data = json.loads(raw_data)['data']\n",
    "#             print(data)\n",
    "#                 # Get a prediction from the model\n",
    "#             int_features = data\n",
    "#             int_features.pop(0)\n",
    "#             print(int_features)\n",
    "\n",
    "#             int_features[7]=int_features[7]+int_features[8]\n",
    "#             int_features.pop(8)\n",
    "#             print(int_features)\n",
    "#             final_features = list(int_features)\n",
    "#             print(final_features)\n",
    "#             final_features2=[]\n",
    "#             for i in range(len(final_features)):\n",
    "#                     final_features2.append(l1[i][final_features[i]])\n",
    "#                     print(l1[i][final_features[i]])\n",
    "\n",
    "\n",
    "#             output_encoding=model_feature_dict_output_deos\n",
    "#             output=[]\n",
    "#             for x in output_encoding:\n",
    "#                 print(x)\n",
    "#                 prediction = model_dict_deos[x].predict(np.array(final_features2).reshape(1, -1))\n",
    "\n",
    "\n",
    "\n",
    "#                 pred = prediction[0]\n",
    "#                 output.append(output_encoding[x][pred])\n",
    "        \n",
    "#         if int_features[0]=='ZICR':\n",
    "#         # Get the input data as a numpy array\n",
    "#             l1 = list(model_feature_dict_zicr.values())\n",
    "#             data = json.loads(raw_data)['data']\n",
    "#             print(data)\n",
    "#                 # Get a prediction from the model\n",
    "#             int_features = data\n",
    "#             int_features.pop(0)\n",
    "#             print(int_features)\n",
    "\n",
    "#             int_features[7]=int_features[7]+int_features[8]\n",
    "#             int_features.pop(8)\n",
    "#             print(int_features)\n",
    "#             final_features = list(int_features)\n",
    "#             print(final_features)\n",
    "#             final_features2=[]\n",
    "#             for i in range(len(final_features)):\n",
    "#                     final_features2.append(l1[i][final_features[i]])\n",
    "#                     print(l1[i][final_features[i]])\n",
    "\n",
    "\n",
    "#             output_encoding=model_feature_dict_output_zicr\n",
    "#             output=[]\n",
    "#             for x in output_encoding:\n",
    "#                 print(x)\n",
    "#                 prediction = model_dict_zicr[x].predict(np.array(final_features2).reshape(1, -1))\n",
    "\n",
    "\n",
    "\n",
    "#                 pred = prediction[0]\n",
    "#                 output.append(output_encoding[x][pred])\n",
    "                \n",
    "#         if int_features[0]=='ZBVG':\n",
    "#             l1 = list(model_feature_dict_zbvg.values())\n",
    "#             print(data)\n",
    "#                 # Get a prediction from the model\n",
    "\n",
    "\n",
    "\n",
    "#             int_features.pop(0)\n",
    "#             print(int_features)\n",
    "\n",
    "#             int_features[7]=int_features[7]+int_features[8]\n",
    "#             int_features.pop(8)\n",
    "#             print(int_features)\n",
    "#             final_features = list(int_features)\n",
    "#             print(final_features)\n",
    "#             final_features2=[]\n",
    "#             for i in range(len(final_features)):\n",
    "#                     final_features2.append(l1[i][final_features[i]])\n",
    "#                     print(l1[i][final_features[i]])\n",
    "\n",
    "\n",
    "#             output_encoding=model_feature_dict_output_zbvg\n",
    "\n",
    "#             for x in output_encoding:\n",
    "#                 print(x)\n",
    "#                 prediction = model_dict_zbvg[x].predict(np.array(final_features2).reshape(1, -1))\n",
    "\n",
    "\n",
    "\n",
    "#                 pred = prediction[0]\n",
    "#                 output.append(output_encoding[x][pred])\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#             return json.dumps(output)\n",
    "#     except Exception as e:\n",
    "#         result = str(e)\n",
    "#         # return error message back to the client\n",
    "#         return json.dumps({\"Error Input Wrong\": result})\n",
    "        \n",
    "        \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./statement_final_deos/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model_dict_deos\n",
    "    global model_feature_dict_deos\n",
    "    global model_feature_dict_output_deos\n",
    "    \n",
    "    global model_dict_zicr\n",
    "    global model_feature_zicr\n",
    "    global model_feature_dict_zicr\n",
    "    \n",
    "    global model_dict_zbvg\n",
    "    global model_feature_dict_zbvg\n",
    "    global model_feature_dict_output_zbvg\n",
    "    \n",
    "    global model_dict_zsvr\n",
    "    global model_feature_dict_zsvr\n",
    "    global model_feature_dict_output_zsvr\n",
    "    \n",
    "    global model_dict_zhrc\n",
    "    global model_feature_dict_zhrc\n",
    "    global model_feature_dict_output_zhrc\n",
    "    \n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path1 = Model.get_model_path('model-deos-statement_dict_deos')\n",
    "    model_path2 = Model.get_model_path('model-deos-statement_features_dict_deos')\n",
    "    model_path3 = Model.get_model_path('model-deos-statement_features_output_dict_deos')\n",
    "    model_path4 = Model.get_model_path('model-deos-statement_dict_zicr')\n",
    "    model_path5 = Model.get_model_path('model-deos-statement_features_dict_zicr')\n",
    "    model_path6 = Model.get_model_path('model-deos-statement_features_output_dict_zicr')\n",
    "    model_path7 = Model.get_model_path('model-deos-statement_dict_zbvg')\n",
    "    model_path8 = Model.get_model_path('model-deos-statement_features_dict_zbvg')\n",
    "    model_path9 = Model.get_model_path('model-deos-statement_features_output_dict_zbvg')\n",
    "    model_path10 = Model.get_model_path('model-deos-statement_dict_zhrc')\n",
    "    model_path11 = Model.get_model_path('model-deos-statement_features_dict_zhrc')\n",
    "    model_path12 = Model.get_model_path('model-deos-statement_features_output_dict_zhrc')\n",
    "    model_path13= Model.get_model_path('model-deos-statement_dict_zsvr')\n",
    "    model_path14= Model.get_model_path('model-deos-statement_features_dict_zsvr')\n",
    "    model_path15= Model.get_model_path('model-deos-statement_features_output_dict_zsvr')\n",
    "\n",
    "    \n",
    "    model_dict_deos = joblib.load(model_path1)\n",
    "    model_feature_dict_deos = joblib.load(model_path2)\n",
    "    model_feature_dict_output_deos = joblib.load(model_path3)\n",
    "    \n",
    "    model_dict_zicr = joblib.load(model_path4)\n",
    "    model_feature_dict_zicr = joblib.load(model_path5)\n",
    "    model_feature_dict_output_zicr = joblib.load(model_path6)\n",
    "    \n",
    "    model_dict_zbvg = joblib.load(model_path7)\n",
    "    model_feature_dict_zbvg = joblib.load(model_path8)\n",
    "    model_feature_dict_output_zbvg = joblib.load(model_path9)\n",
    "    \n",
    "    model_dict_zhrc = joblib.load(model_path10)\n",
    "    model_feature_dict_zhrc = joblib.load(model_path11)\n",
    "    model_feature_dict_output_zhrc= joblib.load(model_path12)\n",
    "    \n",
    "    model_dict_zsvr = joblib.load(model_path13)\n",
    "    model_feature_dict_zsvr = joblib.load(model_path14)\n",
    "    model_feature_dict_output_zsvr = joblib.load(model_path15)\n",
    "   \n",
    "\n",
    " \n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    try:\n",
    "    # Get the input data as a numpy array\n",
    "        output=[]\n",
    "        data = json.loads(raw_data)['data']\n",
    "        int_features = data\n",
    "\n",
    "        if int_features[0]=='ZDEO':\n",
    "            l1 = list(model_feature_dict_deos.values())\n",
    "            print(data)\n",
    "                # Get a prediction from the model\n",
    "\n",
    "\n",
    "\n",
    "            int_features.pop(0)\n",
    "            print(int_features)\n",
    "            val = int_features[7]\n",
    "            lang = int_features[8]\n",
    "            int_features[7]=int_features[7]+int_features[8]\n",
    "            int_features.pop(8)\n",
    "            print(int_features)\n",
    "            final_features = list(int_features)\n",
    "            print(final_features)\n",
    "            final_features2=[]\n",
    "            for i in range(len(final_features)):\n",
    "                    final_features2.append(l1[i][final_features[i]])\n",
    "                    print(l1[i][final_features[i]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        a=0\n",
    "        df1=pd.DataFrame()\n",
    "        output_encoding=model_feature_dict_output_deos\n",
    "        df=pd.DataFrame()\n",
    "\n",
    "        for x in output_encoding:\n",
    "        #         print(x)\n",
    "            print('Yes1')\n",
    "            prediction = model_dict_deos[x].predict(np.array(final_features2).reshape(1, -1))\n",
    "\n",
    "            pred = prediction[0]\n",
    "            df= pd.DataFrame(columns=[\"Validity_Area\",\"Language\"], data=[[val,lang]])\n",
    "\n",
    "            df['POSNR']=str(a)\n",
    "            df['purpose'] = x\n",
    "            df['Display'] = 'X'\n",
    "            df['PHR_DESC'] = ''\n",
    "            df['Zsource'] = ''\n",
    "            df['phrase'] = output_encoding[x][pred]\n",
    "            print('Yes1')\n",
    "\n",
    "        #         print(df['phrase'])\n",
    "            if df['phrase'].str.contains(\"No\").bool():\n",
    "\n",
    "                df['POSNR']=str(a)\n",
    "                output.append(list(df.iloc[0]))\n",
    "                a=a+1\n",
    "                print(\"cvbnm\")\n",
    "        #         print(output)\n",
    "            else:\n",
    "\n",
    "                s = df['phrase'].str.split(',').apply(pd.Series, 1).stack()\n",
    "                s.index = s.index.droplevel(-1)\n",
    "                s.name = 'phrase'\n",
    "        #             print(s)\n",
    "                dictionary = {'{':'', '}':'',\"'\":'',' ':''}\n",
    "                s.replace(dictionary,regex =True,inplace =True) \n",
    "                del df['phrase']\n",
    "                df2= df.join(s)\n",
    "        #         print(df2)\n",
    "\n",
    "                df2.reset_index(drop=True,inplace=True)\n",
    "                print('Yes5')\n",
    "                for index, rows in df2.iterrows(): \n",
    "                    if 'GST' in df2['phrase'].iloc[0] or 'SST' in df2['phrase'].iloc[0]:\n",
    "                        df2['Zsource'] = 'CU-PRED'\n",
    "                        df2['POSNR']=str(a)\n",
    "                        a=a+1\n",
    "\n",
    "                    else:\n",
    "                        df2['Zsource'] = 'CU-EDIT'\n",
    "                        df2['POSNR']=str(a)\n",
    "                        a=a+1\n",
    "                    output.append(list(df2.iloc[index]))\n",
    "\n",
    "       \n",
    "        return json.dumps(output)\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        # return error message back to the client\n",
    "        return json.dumps({\"Error Input Wrong\": result})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#int_features = [\"zdeo\",\"BRBH0045\",\"TFC00034\",\"TFS00006\",\"TFT00008\",\"ZPAM_INJCT\",\"Dispenser\",\"Roll-On\",\"AT\",\"Z2\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dependency info in ./statement_final_deos/sm_trial_env.yml\n",
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "    # Required packages for AzureML execution, history, and data preparation.\n",
      "  - azureml-defaults\n",
      "\n",
      "- scikit-learn\n",
      "channels:\n",
      "- anaconda\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "# Add the dependencies for our model (AzureML defaults is already included)\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package('scikit-learn')\n",
    "# Save the environment config as a .yml file\n",
    "env_file = os.path.join(experiment_folder,\"sm_trial_env.yml\")\n",
    "with open(env_file,\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "print(\"Saved dependency info in\", env_file)\n",
    "# Print the .yml file\n",
    "with open(env_file,\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import InferenceConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the scoring environment\n",
    "inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                   entry_script=script_file,\n",
    "                                   conda_file=env_file)\n",
    "\n",
    "# deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1, auth_enabled=True,enable_app_insights=True,\n",
    "#                                                        ssl_enabled=True, ssl_cert_pem_file=\"cert.pem\", ssl_key_pem_file=\"key.pem\", ssl_cname=\"www.myproject.rand.unilever.com\")\n",
    "    \n",
    "\n",
    "# # location=None,\n",
    "# # auth_enabled=True,\n",
    "# # ssl_enabled=True,\n",
    "# # enable_app_insights=True,\n",
    "# # ssl_cert_pem_file=None,\n",
    "# # ssl_key_pem_file=None,\n",
    "# # ssl_cname=None,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the scoring environment\n",
    "\n",
    "from azureml.core.webservice import AksWebservice, Webservice\n",
    "from azureml.core.model import Model\n",
    "\n",
    "\n",
    "\n",
    "from azureml.core.compute import ComputeTarget, AksCompute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If deploying to a cluster configured for dev/test, ensure that it was created with enough\n",
    "# cores and memory to handle this deployment configuration. Note that memory is also used by\n",
    "# things such as dependencies and AML components.\n",
    "deployment_config = AksWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoscale_enabled=None,\n",
    "# autoscale_min_replicas=None,\n",
    "# autoscale_max_replicas=None,\n",
    "# autoscale_refresh_seconds=None,\n",
    "# autoscale_target_utilization=None,\n",
    "# collect_model_data=None,\n",
    "# auth_enabled=None,\n",
    "# cpu_cores=None,\n",
    "# memory_gb=None,\n",
    "# enable_app_insights=None,\n",
    "# scoring_timeout_ms=None,\n",
    "# replica_max_concurrent_requests=None,\n",
    "# max_request_wait_time=None,\n",
    "# num_replicas=None,\n",
    "# primary_key=None,\n",
    "# secondary_key=None,\n",
    "# tags=None,\n",
    "# properties=None,\n",
    "# description=None,\n",
    "# gpu_cores=None,\n",
    "# period_seconds=None,\n",
    "# initial_delay_seconds=None,\n",
    "# timeout_seconds=None,\n",
    "# success_threshold=None,\n",
    "# failure_threshold=None,\n",
    "# namespace=None,\n",
    "# token_auth_enabled=None,\n",
    "# compute_target_name=None,\n",
    "# cpu_cores_limit=None,\n",
    "# memory_gb_limit=None,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "aks_name = 'aksstatements1' \n",
    "cts = ws.compute_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for cluster creation completion...\n",
      "Creating....................................................................................................................................\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "prov_config = AksCompute.provisioning_configuration(\n",
    "                                                       )\n",
    "aks_target = ComputeTarget.create(workspace = ws, \n",
    "                              name = aks_name, \n",
    "                              provisioning_configuration = prov_config)\n",
    "print('Waiting for cluster creation completion...')\n",
    "aks_target.wait_for_completion(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if aks_name in cts and cts[aks_name].type == 'AKS':\n",
    "#     print('Found existing AKS cluster, will use it!')\n",
    "#     aks_target = cts[aks_name]\n",
    "# else:\n",
    "#     print('Creating a new AKS cluster...')\n",
    "#     prov_config = AksCompute.provisioning_configuration(\n",
    "#                                                        )\n",
    "#     aks_target = ComputeTarget.create(workspace = ws, \n",
    "#                                   name = aks_name, \n",
    "#                                   provisioning_configuration = prov_config)\n",
    "#     print('Waiting for cluster creation completion...')\n",
    "#     aks_target.wait_for_completion(show_output = True)\n",
    "# print('Cluster state:', aks_target.provisioning_state)\n",
    "# print('Cluster is ready!', aks_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Model.deploy(ws, \"statement-service\", [model_dict_deos,model_feature_dict_deos,model_feature_dict_output_deos,model_dict_zicr,model_feature_dict_zicr,model_feature_dict_output_zicr,model_dict_zbvg,model_feature_dict_zbvg,model_feature_dict_output_zbvg,model_dict_zsvr,model_feature_dict_zsvr,model_feature_dict_output_zsvr,model_dict_zhrc,model_feature_dict_zhrc,model_feature_dict_output_zhrc], inference_config, deployment_config, aks_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running...........\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "2020-12-17T11:34:44,601968760+00:00 - iot-server/run \n",
      "2020-12-17T11:34:44,602904667+00:00 - rsyslog/run \n",
      "2020-12-17T11:34:44,603241470+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "2020-12-17T11:34:44,606273694+00:00 - gunicorn/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2020-12-17T11:34:44,684098309+00:00 - iot-server/finish 1 0\n",
      "2020-12-17T11:34:44,685394220+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (11)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 41\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2020-12-17 11:34:45,953 | root | INFO | Starting up app insights client\n",
      "Starting up app insights client\n",
      "2020-12-17 11:34:45,954 | root | INFO | Starting up request id generator\n",
      "Starting up request id generator\n",
      "2020-12-17 11:34:45,954 | root | INFO | Starting up app insight hooks\n",
      "Starting up app insight hooks\n",
      "2020-12-17 11:34:45,954 | root | INFO | Invoking user's init function\n",
      "Invoking user's init function\n",
      "/azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.tree.tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.tree. Anything that cannot be imported from sklearn.tree is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.21.3 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "2020-12-17 11:34:46,319 | root | INFO | Users's init has completed successfully\n",
      "Users's init has completed successfully\n",
      "2020-12-17 11:34:46,322 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2020-12-17 11:34:46,322 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2020-12-17 11:34:46,322 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "2020-12-17 11:34:53,080 | root | INFO | Swagger file not present\n",
      "Swagger file not present\n",
      "2020-12-17 11:34:53,080 | root | INFO | 404\n",
      "404\n",
      "127.0.0.1 - - [17/Dec/2020:11:34:53 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"-\"\n",
      "2020-12-17 11:34:53,343 | root | INFO | Swagger file not present\n",
      "Swagger file not present\n",
      "2020-12-17 11:34:53,343 | root | INFO | 404\n",
      "404\n",
      "127.0.0.1 - - [17/Dec/2020:11:34:53 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"curl/7.67.0\"\n",
      "2020-12-17 11:34:54,475 | root | INFO | Swagger file not present\n",
      "Swagger file not present\n",
      "2020-12-17 11:34:54,475 | root | INFO | 404\n",
      "404\n",
      "127.0.0.1 - - [17/Dec/2020:11:34:54 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"-\"\n",
      "2020-12-17 11:35:07,383 | root | INFO | Swagger file not present\n",
      "Swagger file not present\n",
      "2020-12-17 11:35:07,384 | root | INFO | 404\n",
      "404\n",
      "127.0.0.1 - - [17/Dec/2020:11:35:07 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"curl/7.67.0\"\n",
      "2020-12-17 11:35:11,142 | root | INFO | Swagger file not present\n",
      "Swagger file not present\n",
      "2020-12-17 11:35:11,142 | root | INFO | 404\n",
      "404\n",
      "127.0.0.1 - - [17/Dec/2020:11:35:11 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"-\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# service_name = \"statements-phrase-pird\"\n",
    "# service = Model.deploy(ws, service_name, [model_dict_deos,model_feature_dict_deos,model_feature_dict_output_deos,model_dict_zicr,model_feature_dict_zicr,model_feature_dict_output_zicr,model_dict_zbvg,model_feature_dict_zbvg,model_feature_dict_output_zbvg,model_dict_zsvr,model_feature_dict_zsvr,model_feature_dict_output_zsvr,model_dict_zhrc,model_feature_dict_zhrc,model_feature_dict_output_zhrc], inference_config, deployment_config ,overwrite =True)\n",
    "# service.wait_for_deployment(True)\n",
    "# print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('FGYHUrczCjVeTxUgKWJkOJxTdbV74jSo', 'XzUHdCwhmVljaFhmi5yO0fKf39qloVVs')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service.get_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-17T11:34:44,601968760+00:00 - iot-server/run \n",
      "2020-12-17T11:34:44,602904667+00:00 - rsyslog/run \n",
      "2020-12-17T11:34:44,603241470+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "2020-12-17T11:34:44,606273694+00:00 - gunicorn/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2020-12-17T11:34:44,684098309+00:00 - iot-server/finish 1 0\n",
      "2020-12-17T11:34:44,685394220+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (11)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 41\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2020-12-17 11:34:45,953 | root | INFO | Starting up app insights client\n",
      "Starting up app insights client\n",
      "2020-12-17 11:34:45,954 | root | INFO | Starting up request id generator\n",
      "Starting up request id generator\n",
      "2020-12-17 11:34:45,954 | root | INFO | Starting up app insight hooks\n",
      "Starting up app insight hooks\n",
      "2020-12-17 11:34:45,954 | root | INFO | Invoking user's init function\n",
      "Invoking user's init function\n",
      "/azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.tree.tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.tree. Anything that cannot be imported from sklearn.tree is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.21.3 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "2020-12-17 11:34:46,319 | root | INFO | Users's init has completed successfully\n",
      "Users's init has completed successfully\n",
      "2020-12-17 11:34:46,322 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2020-12-17 11:34:46,322 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2020-12-17 11:34:46,322 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "2020-12-17 11:34:53,080 | root | INFO | Swagger file not present\n",
      "Swagger file not present\n",
      "2020-12-17 11:34:53,080 | root | INFO | 404\n",
      "404\n",
      "127.0.0.1 - - [17/Dec/2020:11:34:53 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"-\"\n",
      "2020-12-17 11:34:53,343 | root | INFO | Swagger file not present\n",
      "Swagger file not present\n",
      "2020-12-17 11:34:53,343 | root | INFO | 404\n",
      "404\n",
      "127.0.0.1 - - [17/Dec/2020:11:34:53 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"curl/7.67.0\"\n",
      "2020-12-17 11:34:54,475 | root | INFO | Swagger file not present\n",
      "Swagger file not present\n",
      "2020-12-17 11:34:54,475 | root | INFO | 404\n",
      "404\n",
      "127.0.0.1 - - [17/Dec/2020:11:34:54 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"-\"\n",
      "2020-12-17 11:35:07,383 | root | INFO | Swagger file not present\n",
      "Swagger file not present\n",
      "2020-12-17 11:35:07,384 | root | INFO | 404\n",
      "404\n",
      "127.0.0.1 - - [17/Dec/2020:11:35:07 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"curl/7.67.0\"\n",
      "2020-12-17 11:35:11,142 | root | INFO | Swagger file not present\n",
      "Swagger file not present\n",
      "2020-12-17 11:35:11,142 | root | INFO | 404\n",
      "404\n",
      "127.0.0.1 - - [17/Dec/2020:11:35:11 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"-\"\n",
      "2020-12-17 11:35:20,206 | root | INFO | Swagger file not present\n",
      "Swagger file not present\n",
      "2020-12-17 11:35:20,206 | root | INFO | 404\n",
      "404\n",
      "127.0.0.1 - - [17/Dec/2020:11:35:20 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"curl/7.67.0\"\n",
      "2020-12-17 11:35:51,595 | root | INFO | Validation Request Content-Type\n",
      "Validation Request Content-Type\n",
      "2020-12-17 11:35:51,596 | root | INFO | \tHost: 52.174.71.177\n",
      "\tHost: 52.174.71.177\n",
      "2020-12-17 11:35:51,596 | root | INFO | \tX-Real-Ip: 10.244.1.3\n",
      "\tX-Real-Ip: 10.244.1.3\n",
      "2020-12-17 11:35:51,596 | root | INFO | \tX-Forwarded-For: 10.244.1.3\n",
      "\tX-Forwarded-For: 10.244.1.3\n",
      "2020-12-17 11:35:51,596 | root | INFO | \tX-Forwarded-Proto: http\n",
      "\tX-Forwarded-Proto: http\n",
      "2020-12-17 11:35:51,596 | root | INFO | \tConnection: close\n",
      "\tConnection: close\n",
      "2020-12-17 11:35:51,596 | root | INFO | \tContent-Length: 106\n",
      "\tContent-Length: 106\n",
      "2020-12-17 11:35:51,596 | root | INFO | \tUser-Agent: curl/7.47.0\n",
      "\tUser-Agent: curl/7.47.0\n",
      "2020-12-17 11:35:51,596 | root | INFO | \tContent-Type: application/json\n",
      "\tContent-Type: application/json\n",
      "2020-12-17 11:35:51,596 | root | INFO | \tAccept: */*\n",
      "\tAccept: */*\n",
      "2020-12-17 11:35:51,597 | root | INFO | \tX-Ms-Request-Id: c775bed2-1e1e-460d-a387-3ba416d565d4\n",
      "\tX-Ms-Request-Id: c775bed2-1e1e-460d-a387-3ba416d565d4\n",
      "2020-12-17 11:35:51,597 | root | INFO | Scoring Timer is set to 3600.0 seconds\n",
      "Scoring Timer is set to 3600.0 seconds\n",
      "['ZDEO', 'BRBH0045', 'TFC00034', 'TFS00006', 'TFT00008', 'ZPAM_INJCT', 'Dispenser', 'Roll-On', 'AT', 'Z2']\n",
      "['BRBH0045', 'TFC00034', 'TFS00006', 'TFT00008', 'ZPAM_INJCT', 'Dispenser', 'Roll-On', 'AT', 'Z2']\n",
      "['BRBH0045', 'TFC00034', 'TFS00006', 'TFT00008', 'ZPAM_INJCT', 'Dispenser', 'Roll-On', 'ATZ2']\n",
      "['BRBH0045', 'TFC00034', 'TFS00006', 'TFT00008', 'ZPAM_INJCT', 'Dispenser', 'Roll-On', 'ATZ2']\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "8\n",
      "7\n",
      "18\n",
      "2\n",
      "Yes1\n",
      "Yes1\n",
      "cvbnm\n",
      "Yes1\n",
      "Yes1\n",
      "Yes5\n",
      "Yes1\n",
      "Yes1\n",
      "cvbnm\n",
      "Yes1\n",
      "Yes1\n",
      "cvbnm\n",
      "2020-12-17 11:35:51,627 | root | INFO | 200\n",
      "200\n",
      "127.0.0.1 - - [17/Dec/2020:11:35:51 +0000] \"POST /score HTTP/1.0\" 200 478 \"-\" \"curl/7.47.0\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consuming the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# x_new =[\"zdeo\",\"BRBH0045\",\"TFC00034\",\"TFS00006\",\"TFT00008\",\"ZPAM_INJCT\",\"Dispenser\",\"Roll-On\",\"AT\",\"Z2\"]\n",
    "# print ('statements: {}'.format(x_new[0]))\n",
    "# # Convert the array to a serializable list in a JSON document\n",
    "# input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "\n",
    "# #a= np.array(json.loads(input_json)['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Call the web service, passing the input data (the web service will also accept the data in binary format)\n",
    "# predictions = service.run(input_data = input_json)\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -X POST \\\n",
    "# \t-H 'Content-Type':'application/json' \\\n",
    "# \t-d '{\"data\":[\"zdeo\",\"BRBH0045\",\"TFC00034\",\"TFS00006\",\"TFT00008\",\"ZPAM_INJCT\",\"Dispenser\",\"Roll-On\",\"AT\",\"Z2\"]}' \\\n",
    "# \thttp://048a1a69-c27a-484b-bbb4-77e21fb216ac.westeurope.azurecontainer.io/score--without keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://52.174.71.177:80/api/v1/service/statement-service/score\n"
     ]
    }
   ],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"[[\\\"AT\\\", \\\"Z2\\\", \\\"0\\\", \\\"SYMBOLS/LOGOS\\\", \\\"X\\\", \\\"\\\", \\\"\\\", \\\"No_SYMBOLS/LOGOS_phrase\\\"], [\\\"AT\\\", \\\"Z2\\\", \\\"1\\\", \\\"SAFETY_INSTRUCTIONS\\\", \\\"X\\\", \\\"\\\", \\\"CU-PRED\\\", \\\"CUST-GST00000057\\\"], [\\\"AT\\\", \\\"Z2\\\", \\\"2\\\", \\\"SAFETY_INSTRUCTIONS\\\", \\\"X\\\", \\\"\\\", \\\"CU-PRED\\\", \\\"CUST-GST00000058\\\"], [\\\"AT\\\", \\\"Z2\\\", \\\"3\\\", \\\"LEGAL_ENTITY\\\", \\\"X\\\", \\\"\\\", \\\"\\\", \\\"No_LEGAL_ENTITY_phrase\\\"], [\\\"AT\\\", \\\"Z2\\\", \\\"4\\\", \\\"USE_INSTRUCTIONS\\\", \\\"X\\\", \\\"\\\", \\\"\\\", \\\"No_USE_INSTRUCTIONS_phrase\\\"]]\""
     ]
    }
   ],
   "source": [
    "!curl -X POST \\\n",
    "\t-H 'Content-Type':'application/json' \\\n",
    "\t-H \"Authorization: Bearer FGYHUrczCjVeTxUgKWJkOJxTdbV74jSo\"\\\n",
    "\t-d '{\"data\":[\"ZDEO\",\"BRBH0045\",\"TFC00034\",\"TFS00006\",\"TFT00008\",\"ZPAM_INJCT\",\"Dispenser\",\"Roll-On\",\"AT\",\"Z2\"]}' \\\n",
    "\thttp://52.174.71.177:80/api/v1/service/statement-service/score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://52.174.71.177:80/api/v1/service/statement-service/score\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/plm-ml-team-compute1/code/Users/Shashank.Awasthi/NEW_DEPLOY'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model_feature_dict_output_deos=joblib.load(\"final_encoding_output_zdeo.pkl\")\n",
    "model_feature_dict_deos=joblib.load(\"final_encoding_zdeo.pkl\")\n",
    "model_dict_deos=joblib.load(\"dict_model_zdeo.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile $script_file\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from azureml.core.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the input data as a numpy array\n",
    "output=[]\n",
    "#     data = json.loads(raw_data)['data']\n",
    "data = [\"ZDEO\",\"BRBH0045\",\"TFC00034\",\"TFS00006\",\"TFT00008\",\"ZPAM_INJCT\",\"Dispenser\",\"Roll-On\",\"AT\",\"Z2\"]\n",
    "int_features = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ZDEO', 'BRBH0045', 'TFC00034', 'TFS00006', 'TFT00008', 'ZPAM_INJCT', 'Dispenser', 'Roll-On', 'AT', 'Z2']\n"
     ]
    }
   ],
   "source": [
    "l1 = list(model_feature_dict_deos.values())\n",
    "print(data)\n",
    "    # Get a prediction from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BRBH0045', 'TFC00034', 'TFS00006', 'TFT00008', 'ZPAM_INJCT', 'Dispenser', 'Roll-On', 'AT', 'Z2']\n"
     ]
    }
   ],
   "source": [
    "int_features.pop(0)\n",
    "print(int_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BRBH0045', 'TFC00034', 'TFS00006', 'TFT00008', 'ZPAM_INJCT', 'Dispenser', 'Roll-On', 'ATZ2']\n",
      "['BRBH0045', 'TFC00034', 'TFS00006', 'TFT00008', 'ZPAM_INJCT', 'Dispenser', 'Roll-On', 'ATZ2']\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "8\n",
      "7\n",
      "19\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "val = int_features[7]\n",
    "lang = int_features[8]\n",
    "int_features[7]=int_features[7]+int_features[8]\n",
    "int_features.pop(8)\n",
    "print(int_features)\n",
    "final_features = list(int_features)\n",
    "print(final_features)\n",
    "final_features2=[]\n",
    "for i in range(len(final_features)):\n",
    "        final_features2.append(l1[i][final_features[i]])\n",
    "        print(l1[i][final_features[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\"ZDEO\",\"BRBH0045\",\"TFC00034\",\"TFS00006\",\"TFT00008\",\"ZPAM_INJCT\",\"Dispenser\",\"Roll-On\",\"AT\",\"Z2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ZDEO', 'BRBH0045', 'TFC00034', 'TFS00006', 'TFT00008', 'ZPAM_INJCT', 'Dispenser', 'Roll-On', 'AT', 'Z2']\n",
      "['BRBH0045', 'TFC00034', 'TFS00006', 'TFT00008', 'ZPAM_INJCT', 'Dispenser', 'Roll-On', 'AT', 'Z2']\n",
      "['BRBH0045', 'TFC00034', 'TFS00006', 'TFT00008', 'ZPAM_INJCT', 'Dispenser', 'Roll-On', 'ATZ2']\n",
      "['BRBH0045', 'TFC00034', 'TFS00006', 'TFT00008', 'ZPAM_INJCT', 'Dispenser', 'Roll-On', 'ATZ2']\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "8\n",
      "7\n",
      "19\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['AT', 'Z2', '0', 'SYMBOLS/LOGOS', 'X', '', '', 'No_SYMBOLS/LOGOS_phrase'],\n",
       " ['AT',\n",
       "  'Z2',\n",
       "  '1',\n",
       "  'USE_INSTRUCTIONS',\n",
       "  'X',\n",
       "  '',\n",
       "  '',\n",
       "  'No_USE_INSTRUCTIONS_phrase'],\n",
       " ['AT',\n",
       "  'Z2',\n",
       "  '2',\n",
       "  'SAFETY_INSTRUCTIONS',\n",
       "  'X',\n",
       "  '',\n",
       "  'CU-PRED',\n",
       "  'CUST-GST00000057'],\n",
       " ['AT',\n",
       "  'Z2',\n",
       "  '3',\n",
       "  'SAFETY_INSTRUCTIONS',\n",
       "  'X',\n",
       "  '',\n",
       "  'CU-PRED',\n",
       "  'CUST-GST00000058'],\n",
       " ['AT', 'Z2', '4', 'LEGAL_ENTITY', 'X', '', '', 'No_LEGAL_ENTITY_phrase']]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#         data = json.loads(raw_data)['data']\n",
    "data = [\"ZDEO\",\"BRBH0045\",\"TFC00034\",\"TFS00006\",\"TFT00008\",\"ZPAM_INJCT\",\"Dispenser\",\"Roll-On\",\"AT\",\"Z2\"]\n",
    "int_features = data\n",
    "\n",
    "\n",
    "if int_features[0]=='ZDEO':\n",
    "    l1 = list(model_feature_dict_deos.values())\n",
    "    print(data)\n",
    "        # Get a prediction from the model\n",
    "\n",
    "\n",
    "\n",
    "    int_features.pop(0)\n",
    "    print(int_features)\n",
    "    val = int_features[7]\n",
    "    lang = int_features[8]\n",
    "    int_features[7]=int_features[7]+int_features[8]\n",
    "    int_features.pop(8)\n",
    "    print(int_features)\n",
    "    final_features = list(int_features)\n",
    "    print(final_features)\n",
    "    final_features2=[]\n",
    "    for i in range(len(final_features)):\n",
    "            final_features2.append(l1[i][final_features[i]])\n",
    "            print(l1[i][final_features[i]])\n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "\n",
    "\n",
    "a=0\n",
    "df1=pd.DataFrame()\n",
    "output_encoding=model_feature_dict_output_deos\n",
    "df=pd.DataFrame()\n",
    "\n",
    "for x in output_encoding:\n",
    "#         print(x)\n",
    "    prediction = model_dict_deos[x].predict(np.array(final_features2).reshape(1, -1))\n",
    "\n",
    "    pred = prediction[0]\n",
    "    df= pd.DataFrame(columns=[\"Validity_Area\",\"Language\"], data=[[val,lang]])\n",
    "    \n",
    "    df['POSNR']=str(a)\n",
    "    df['purpose'] = x\n",
    "    df['Display'] = 'X'\n",
    "    df['PHR_DESC'] = ''\n",
    "    df['Zsource'] = ''\n",
    "    df['phrase'] = output_encoding[x][pred]\n",
    "    \n",
    "    \n",
    "#         print(df['phrase'])\n",
    "    if df['phrase'].str.contains(\"No\").bool():\n",
    "        \n",
    "        df['POSNR']=str(a)\n",
    "        output.append(list(df.iloc[0]))\n",
    "        a=a+1\n",
    "#         print(\"\")\n",
    "#         print(output)\n",
    "    else:\n",
    "        \n",
    "        s = df['phrase'].str.split(',').apply(pd.Series, 1).stack()\n",
    "        s.index = s.index.droplevel(-1)\n",
    "        s.name = 'phrase'\n",
    "#             print(s)\n",
    "        dictionary = {'{':'', '}':'',\"'\":'',' ':''}\n",
    "        s.replace(dictionary,regex =True,inplace =True) \n",
    "        del df['phrase']\n",
    "        df2= df.join(s)\n",
    "#         print(df2)\n",
    "        \n",
    "        df2.reset_index(drop=True,inplace=True)\n",
    "        \n",
    "        for index, rows in df2.iterrows(): \n",
    "            if 'GST' in df2['phrase'].iloc[0] or 'SST' in df2['phrase'].iloc[0]:\n",
    "                df2['Zsource'] = 'CU-PRED'\n",
    "                df2['POSNR']=str(a)\n",
    "                a=a+1\n",
    "                \n",
    "            else:\n",
    "                df2['Zsource'] = 'CU-EDIT'\n",
    "                df2['POSNR']=str(a)\n",
    "                a=a+1\n",
    "            output.append(list(df2.iloc[index]))\n",
    "    json.dumps(output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[\"AT\", \"Z2\", \"0\", \"SYMBOLS/LOGOS\", \"X\", \"\", \"\", \"No_SYMBOLS/LOGOS_phrase\"], [\"AT\", \"Z2\", \"1\", \"USE_INSTRUCTIONS\", \"X\", \"\", \"\", \"No_USE_INSTRUCTIONS_phrase\"], [\"AT\", \"Z2\", \"2\", \"SAFETY_INSTRUCTIONS\", \"X\", \"\", \"CU-PRED\", \"CUST-GST00000057\"], [\"AT\", \"Z2\", \"3\", \"SAFETY_INSTRUCTIONS\", \"X\", \"\", \"CU-PRED\", \"CUST-GST00000058\"], [\"AT\", \"Z2\", \"4\", \"LEGAL_ENTITY\", \"X\", \"\", \"\", \"No_LEGAL_ENTITY_phrase\"]]'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(output)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if int_features[0]=='ZDEO':\n",
    "    l1 = list(model_feature_dict_deos.values())\n",
    "    print(data)\n",
    "        # Get a prediction from the model\n",
    "\n",
    "\n",
    "\n",
    "    int_features.pop(0)\n",
    "    print(int_features)\n",
    "    val = int_features[7]\n",
    "    lang = int_features[8]\n",
    "    int_features[7]=int_features[7]+int_features[8]\n",
    "    int_features.pop(8)\n",
    "    print(int_features)\n",
    "    final_features = list(int_features)\n",
    "    print(final_features)\n",
    "    final_features2=[]\n",
    "    for i in range(len(final_features)):\n",
    "            final_features2.append(l1[i][final_features[i]])\n",
    "            print(l1[i][final_features[i]])\n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "\n",
    "\n",
    "a=0\n",
    "df1=pd.DataFrame()\n",
    "output_encoding=model_feature_dict_output_deos\n",
    "df=pd.DataFrame()\n",
    "\n",
    "for x in output_encoding:\n",
    "#         print(x)\n",
    "    prediction = model_dict_deos[x].predict(np.array(final_features2).reshape(1, -1))\n",
    "\n",
    "    pred = prediction[0]\n",
    "    df= pd.DataFrame(columns=[\"Validity_Area\",\"Language\"], data=[[val,lang]])\n",
    "    \n",
    "    df['POSNR']=str(a)\n",
    "    df['purpose'] = x\n",
    "    df['Display'] = 'X'\n",
    "    df['PHR_DESC'] = ''\n",
    "    df['Zsource'] = ''\n",
    "    df['phrase'] = output_encoding[x][pred]\n",
    "    \n",
    "    \n",
    "#         print(df['phrase'])\n",
    "    if df['phrase'].str.contains(\"No\").bool():\n",
    "        \n",
    "        df['POSNR']=str(a)\n",
    "        output.append(list(df.iloc[0]))\n",
    "        a=a+1\n",
    "#         print(\"\")\n",
    "#         print(output)\n",
    "    else:\n",
    "        \n",
    "        s = df['phrase'].str.split(',').apply(pd.Series, 1).stack()\n",
    "        s.index = s.index.droplevel(-1)\n",
    "        s.name = 'phrase'\n",
    "#             print(s)\n",
    "        dictionary = {'{':'', '}':'',\"'\":'',' ':''}\n",
    "        s.replace(dictionary,regex =True,inplace =True) \n",
    "        del df['phrase']\n",
    "        df2= df.join(s)\n",
    "#         print(df2)\n",
    "        \n",
    "        df2.reset_index(drop=True,inplace=True)\n",
    "        \n",
    "        for index, rows in df2.iterrows(): \n",
    "            if 'GST' in df2['phrase'].iloc[0] or 'SST' in df2['phrase'].iloc[0]:\n",
    "                df2['Zsource'] = 'CU-PRED'\n",
    "                df2['POSNR']=str(a)\n",
    "                a=a+1\n",
    "                \n",
    "            else:\n",
    "                df2['Zsource'] = 'CU-EDIT'\n",
    "                df2['POSNR']=str(a)\n",
    "                a=a+1\n",
    "            output.append(list(df2.iloc[index]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
